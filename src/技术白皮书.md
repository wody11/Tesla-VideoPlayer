基于浏览器的内核级播放器
1. 背景与目标

传统问题
浏览器 <video> 标签或 MSE/EME 模块限制多：

格式有限（通常是 MP4/HLS），无法灵活支持多协议。

内核不可控，时钟同步、解码策略无法干预。

扩展性差，无法轻松接入 GPU 滤镜、AI 后处理。

目标
构建一个完全自主的“内核级播放器”，从 拉流 → 解复用 → 比特流适配 → 解码 → 渲染/播放 全链路由我们掌控，对标 ffplay 模型，但运行在浏览器环境。

2. 系统架构
2.1 架构图
[输入源: HLS/MP4/WS] 
   ↓
[IOReader/Buffer 管理] 
   ↓
[Demux(TS/MP4)] 
   ↓
[比特流过滤器(BSF): AnnexB↔AVCC, ADTS→RAW]
   ↓
[Packet 队列]
   ↓
+------------------+------------------+
| VideoDecoder(WebCodecs/WASM)       |
| AudioDecoder(WebCodecs/WASM)       |
+------------------+------------------+
   ↓                              ↓
[Frame 队列]                  [Audio 队列]
   ↓                              ↓
[Canvas/WebGL/WebGPU 渲染]      [WebAudio 输出]

2.2 线程划分

Main Thread：UI 渲染、Canvas 绘制、用户交互。

Worker：IO、Demux、解码调度。

AudioContext：独立时钟，保证同步。

3. 输入与 IO

支持协议

HLS（m3u8 + TS 切片）。

Progressive MP4。

WebSocket/RTC 扩展。

# 技术白皮书：基于浏览器的“内核级”播放器设计

简要说明：本文档描述一个在浏览器中尽量靠近“内核”控制的播放器架构，覆盖拉流、解复用、比特流适配、解码与渲染全链路，目标是实现可控、可扩展且延展到 WebGPU/AI 后处理的播放框架。

目录
- 背景与目标
- 系统架构（模块与线程划分）
- 输入与 IO
- 解复用（Demux）
- 比特流适配（BSF）
- 时间基与时钟
- Seek 与点播
- 解码（硬件/软件）
- 渲染层
- 播放控制与事件
- 健壮性与错误处理
- 扩展性与与 ffplay 对比
- 实现路线与下一步

---

## 1. 背景与目标

问题点：

- 浏览器原生 `<video>` / MSE/EME 在协议、可控性、后处理扩展方面存在限制。
- 无法对解码/时钟/渲染做内核级别的策略控制（例如插入自定义滤镜、AI 后处理、精细的时钟补偿）。

目标：

构建一个可控的“内核级播放器”——从拉流到渲染的完整链路在我们的框架内可控（参考 ffplay 的工作方式，但运行在浏览器环境，优先使用 WebCodecs）。

## 2. 系统架构（总体）

简化数据流：

[输入源: HLS / MP4 / FLV / WebSocket] → IOReader/缓冲 → Demux(TS/MP4/FLV) → BSF(AnnexB↔AVCC, ADTS→RAW) → Packet 队列 → 解码器 → 渲染/输出

线程划分：

- Main Thread：UI、Canvas 渲染、解码器创建/管理、播放控制。
- Worker：网络 IO、Demux、时间基校正、样本打包（将 ES 以 sample 消息发回主线程）。
- AudioContext：作为主时钟（主线程侧），保证 AV 同步。

架构示意（ASCII）：

```
Main Thread                      Worker
───────────────┐                 ┌───────────────
 UI / Controls │ postMessage()   │ IOReader (fetch/stream)
 Renderer(Canvas)◀───────────────┤ Playlist(HLS) → Demux(TS/MP4/FLV)
 VideoDecoder  │                 │ BSF (AnnexB/AVCC, ADTS→RAW)
 AudioDecoder  │                 │ Packetizer → post(sample)
 AudioSink     │                 └───────────────
```

## 3. 输入与 IO

支持：HLS (m3u8+TS)、Progressive MP4、HTTP-FLV、WebSocket/RTC 扩展。

IOReader 接口建议：

- read(len)
- seek(pos)
- fileSize()
- abort()

缓存策略：高/低水位、实时流使用环形缓冲（RingBuffer）、分片并行度 1-2 以降低内存占用。

## 4. 解复用（Demux）

### 4.1 TS 解析要点

- 固定包长 188B，包头 0x47。
- PAT/PMT → 获取 vPid / aPid 与 streamType（示例：0x1B = H.264, 0x0F = AAC）。
- PES：解析 PTS/DTS（33-bit），拼接 payload。
- Adaptation field 含 PCR、随机接入信息。

可靠性：使用 continuity counter 检测丢包、乱序并做容错处理。

### 4.2 MP4 处理

- 支持 ftyp / moov / moof / mdat，建议复用 mp4box.js 或自研轻量解析器。
- 从 moov/track 提取 avcC / esds，构建解码配置（SPS/PPS / ASC）。

### 4.3 音频解析

- AAC ADTS：每帧 7 或 9 字节头，通常 1024 样本。
- 生成 AudioSpecificConfig (ASC) 供 AudioDecoder 使用。

## 5. 比特流适配（BSF）

目的：在容器与解码器之间转换比特流格式，确保首帧可解码并动态更新 extradata。

主要工作：

- H.264：Annex B ↔ AVCC（AnnexB 使用 0x00000001 起始码，AVCC 使用长度前缀）。
- 提取 SPS/PPS 构造 avcC，用于 VideoDecoder.configure({ description }).
- AAC：ADTS → RAW，构造 ASC（AudioSpecificConfig）。

示例：统一的 Sample 结构

```ts
type Sample = {
  kind: 'video' | 'audio';
  tsUs: number;    // PTS, 单位微秒
  durUs: number;   // duration, 微秒
  key: boolean;    // video keyframe
  data: ArrayBuffer; // AnnexB 或 RAW AAC（传输为 Transferable）
}
```

## 6. 时间基与时钟

- TS 默认时间基：90kHz（PTS/DTS 以 90kHz 为单位）。
- 精度：使用 BigInt 计算时间差以避免溢出/精度损失。
- 同步策略：以音频（AudioContext.currentTime）为时钟基线；视频根据 PTS 对齐渲染。视频落后采取丢帧策略，过快则等待音频时钟。

## 7. Seek 与点播

- MP4 点播：建议使用 moov 算法或二分查找快速定位 sample table，并对齐 IDR。
- TS 点播：估算偏移 + 回退到最近 IDR。
- HLS（直播）：不支持随意 seek，采用分段滚动窗口。

## 8. 解码

### 8.1 硬件解码（优先）

- 使用 WebCodecs：VideoDecoder / AudioDecoder。
- Codec 示例：视频 `avc1.42E01E`，音频 `mp4a.40.2`。
- 配置示例：

```js
videoDecoder.configure({ codec: 'avc1.42E01E', description: avcCUint8Array });
audioDecoder.configure({ codec: 'mp4a.40.2', numberOfChannels: 2, sampleRate: 48000, description: ascUint8Array });
```

### 8.2 软件解码（Fallback）

- 当浏览器不支持硬件 codec 时，使用 WASM（如 ffmpeg.wasm）作为软件解码备选。仅在必要时启用以节省 CPU。

## 9. 渲染层

- 视频：Canvas2D（简单）或 WebGL/WebGPU（高性能/后处理）。
- 音频：WebAudio（AudioWorklet 可用于更低延迟的处理与混音）。

渲染循环策略：主线程按音频时钟消费视频帧队列（例如基于 audioSink.currentTime），并在合适时刻调用 renderer.draw(frame)。

## 10. 播放控制与事件

功能：Play / Pause / Stop / Seek / 速率控制（通过 Audio playbackRate 和视频时间戳缩放）。

事件回调：onBuffering, onPlaying, onEnded, onError。

## 11. 健壮性设计

- TS 丢包：检测并跳过损坏区块，等待下一个 PUSI 或 IDR。
- SPS/PPS 丢失：Worker 等待并缓存 NALU，直到获得 SPS/PPS 后再发出配置与首帧；否则继续等待 IDR。
- Audio 参数变化：自动生成并下发新的 ASC，重新 configure AudioDecoder。
- Worker 崩溃：主线程可检测并重启 Worker，同时使用 generationId 丢弃旧消息。

## 12. 扩展性

- 协议：支持扩展到 FLV、DASH、WebRTC 数据通道等。
- Codec：预留 HEVC / VP9 / AV1 / Opus 的拓展点，可通过 WebCodecs 或 WASM 实现。
- DRM：未来可接入 EME/Widevine。
- AI：在 WebGL/WebGPU 层结合超分、降噪等模型处理 VideoFrame。

## 13. 与 ffplay 的对比（简表）

| 功能 | ffplay (C/SDL) | 本方案 (JS / WebCodecs) |
|---|---:|---:|
| 输入协议 | 几乎所有 | HLS / MP4 / FLV / WebSocket |
| 解复用 | ffmpeg demuxer | JS demux (TS / MP4 / FLV) |
| 解码 | ffmpeg codec | WebCodecs / WASM |
| 时钟同步 | AV sync | AudioContext 时钟 |
| 渲染 | SDL2 | Canvas / WebGL / WebGPU |
| 可控性 | 完全可控 | 我们控制大部分链路 |

## 14. 实现路线（建议分阶段）

1. HLS VOD（WebCodecs 硬解）——实现 Demux(TS)、BSF、主/Worker 通信、Canvas2D + WebAudio。
2. MP4 点播与 Seek 功能；完善 sample table 读取（mp4box 或自研）。
3. 软件解码（WASM）与软硬切换策略；完善错误恢复与回退。
4. 高级渲染：WebGL / WebGPU 后处理、AI 插件、滤镜。

---

## 附录 A：通信协议示例（Worker ↔ Main）

主→工：

```json
{ "type": "openHLS", "url": "https://.../playlist.m3u8" }
{ "type": "openFLV", "url": "https://.../live.flv" }
{ "type": "seek", "ms": 120000 }
{ "type": "close" }
```

工→主：

```json
{ "type": "ready", "durationMs": 123456, "video": { "codec": "avc1...", "description": "ArrayBuffer" }, "audio": {...} }
{ "type": "sample", "kind": "video", "ts": 12345678, "dur": 33333, "key": true, "data": "ArrayBuffer" }
{ "type": "log", "msg": "flushVideoAU: key=true ..." }
```

## 附录 B：关键数据转换样例

### avcC 描述（简化）

```
[ 1 | profile | compat | level | 0xff | 0xe1 | sps_len(2) | SPS | 0x01 | pps_len(2) | PPS ]
```

### Sample 统一结构（TypeScript）

```ts
interface Sample {
  kind: 'video' | 'audio';
  tsUs: number; // PTS in microseconds
  durUs: number;
  key: boolean;
  data: ArrayBuffer;
}
```

